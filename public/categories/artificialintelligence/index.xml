<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ArtificialIntelligence on Rakesh Core</title>
    <link>//localhost:1313/categories/artificialintelligence/</link>
    <description>Recent content in ArtificialIntelligence on Rakesh Core</description>
    <generator>Hugo</generator>
    <language>en</language>
    <atom:link href="//localhost:1313/categories/artificialintelligence/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Artificial Intelligence</title>
      <link>//localhost:1313/docs/artificial-intelligence/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/docs/artificial-intelligence/</guid>
      <description></description>
    </item>
    <item>
      <title>Ollama</title>
      <link>//localhost:1313/docs/artificial-intelligence/ollama/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/docs/artificial-intelligence/ollama/</guid>
      <description>&lt;p&gt;Prerequirement&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;GPU &amp;ndash; good news/bad news - it works/it works badly&#xA;&lt;a href=&#34;https://ollama.com/blog/amd-preview&#34;&gt;https://ollama.com/blog/amd-preview&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;docker run -d -p 3001:8080 -e OLLAMA_BASE_URL=http://&amp;lt;REMOTE_SERVER_IP&amp;gt;:11434/  &amp;ndash;name open-webui &amp;ndash;restart always ghcr.io/open-webui/open-webui:main&lt;/p&gt;&#xA;&lt;p&gt;ollama &amp;ndash; lLM runner&lt;/p&gt;&#xA;&lt;h1 id=&#34;installation-of-ollama&#34;&gt;Installation of ollama&lt;/h1&gt;&#xA;&lt;p&gt;manual installation - custom configuration&#xA;&lt;a href=&#34;https://ollama.com/blog/ollama-is-now-available-as-an-official-docker-image&#34;&gt;https://ollama.com/blog/ollama-is-now-available-as-an-official-docker-image&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;expain installation shell script&lt;/p&gt;&#xA;&lt;p&gt;LLM,SLM, large Image model&lt;/p&gt;&#xA;&lt;h1 id=&#34;companies-which-creates-models&#34;&gt;Companies which creates models&lt;/h1&gt;&#xA;&lt;h1 id=&#34;possible-options-to-use-ai-models&#34;&gt;Possible options to use AI models&lt;/h1&gt;&#xA;&lt;p&gt;ollama &lt;a href=&#34;https://github.com/ollama/ollama&#34;&gt;https://github.com/ollama/ollama&lt;/a&gt;&#xA;azure&amp;rsquo;s openai offering&#xA;openai&lt;/p&gt;&#xA;&lt;h1 id=&#34;tool-kit&#34;&gt;Tool kit&lt;/h1&gt;&#xA;&lt;p&gt;ROCm and CUDA&lt;/p&gt;&#xA;&lt;h1 id=&#34;terminologies-with-respect-to-ai&#34;&gt;Terminologies with respect to AI&lt;/h1&gt;&#xA;&lt;p&gt;What is a token &amp;ndash;?&#xA;what is a model &amp;ndash;? create a modelfile&#xA;what is a dataset?&#xA;what is training?&#xA;what is fine-tuning model&amp;ndash;?&#xA;what is instruct model ?&#xA;what is prompt &amp;ndash;? vary based on model&#xA;tool calling ?&#xA;NLP?&#xA;Transformers?&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
